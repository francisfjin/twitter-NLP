{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBErZMC6qBOB"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "6IihA3b6NLaa",
    "outputId": "b5dad4ee-8200-4784-a9b6-de026d379ae7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "DbJiHNhgqacw",
    "outputId": "7eaf87c2-a382-414a-c6e4-70ce7ae26e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-twitter in /usr/local/lib/python3.6/dist-packages (3.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from python-twitter) (2.23.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.6/dist-packages (from python-twitter) (1.3.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from python-twitter) (0.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->python-twitter) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->python-twitter) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->python-twitter) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->python-twitter) (3.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib->python-twitter) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-twitter\n",
    "import twitter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "b4ziyFwPrQpm",
    "outputId": "691dd43a-7abd-4a37-de56-196b6c438087"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import string\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "import tweepy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from string import punctuation \n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.preprocessing import label_binarize, MultiLabelBinarizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding,LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "punctuations = string.punctuation\n",
    "#nlp = spacy.load('en_core_web_md')\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dg8Bzp7K2QNx"
   },
   "outputs": [],
   "source": [
    "APIkey = 'YOURAPIKEY'\n",
    "APIsecretkey = 'YOURAPISECRETKEY'\n",
    "accesstokensecret = 'ACCESSTOKENSECRET'\n",
    "accesstoken = 'ACCESSTOKEN'\n",
    "\n",
    "twitter_api = twitter.Api(consumer_key=APIkey,consumer_secret=APIsecretkey,access_token_key=accesstoken,access_token_secret=accesstokensecret)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "amPZuW1tqNWh"
   },
   "source": [
    "# Search Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcysLFMx4ZCI"
   },
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(APIkey, APIsecretkey )\n",
    "auth.set_access_token(accesstoken, accesstokensecret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "tweets = []\n",
    "\n",
    "def querytweets(text_query, count):\n",
    "#tweepy API to query tweets for desired search term\n",
    "        tweets = tweepy.Cursor(api.search, q=text_query, lang='en', \n",
    "                               #geocode=coordinates,\n",
    "                               ).items(count)\n",
    "        tweets_list = [[tweet.created_at, tweet.text] for tweet in tweets]\n",
    "        tweets_df = pd.DataFrame(tweets_list, columns=['Datetime', 'Text'])\n",
    "        return tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "9Voq0QwR8v_t",
    "outputId": "bc486412-3cc1-46b5-f71e-96b44d3feb3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a search keyword: blackpink\n"
     ]
    }
   ],
   "source": [
    "text_query = input(\"Enter a search keyword: \") \n",
    "\n",
    "#number of desired tweets here\n",
    "count = 10\n",
    "searchsetdf = querytweets(text_query, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "RmSlxryT4Dx7",
    "outputId": "527b7c70-5e36-47a6-da13-8ebfd174b9c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-19 06:44:20</td>\n",
       "      <td>RT @blackpinkbabo: JENNIE LIKES THAT! Look at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-19 06:44:20</td>\n",
       "      <td>RT @ygent_official: #BLACKPINK 'Kill This Love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-19 06:44:19</td>\n",
       "      <td>RT @13chnwar: rosie is whipped ðŸ˜‚\\n\\n#JENNIE #ì œ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-19 06:44:19</td>\n",
       "      <td>RT @BLACKPINKGLOBAL: RT &amp;amp; REPLY:\\n\\nI vote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-19 06:44:19</td>\n",
       "      <td>RT @TODAYonline: Blackpink's Lisa Is M.A.C's F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-10-19 06:44:19</td>\n",
       "      <td>RT @jnyloops: hi! this is a new account dedica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-10-19 06:44:19</td>\n",
       "      <td>RT @TeamLisaEU: ðŸ“Œ #LISA: I have always been a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-10-19 06:44:19</td>\n",
       "      <td>RT @BLACKPINKGLOBAL: #JISOO #JENNIE #ROSÃ‰ for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-10-19 06:44:18</td>\n",
       "      <td>RT @BLACKPINK: 'THE ALBUM' JACKET MAKING FILM\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-10-19 06:44:18</td>\n",
       "      <td>RT @BLINKVotingPage: [PCA 2020]\\n\\nLast year, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Datetime                                               Text\n",
       "0 2020-10-19 06:44:20  RT @blackpinkbabo: JENNIE LIKES THAT! Look at ...\n",
       "1 2020-10-19 06:44:20  RT @ygent_official: #BLACKPINK 'Kill This Love...\n",
       "2 2020-10-19 06:44:19  RT @13chnwar: rosie is whipped ðŸ˜‚\\n\\n#JENNIE #ì œ...\n",
       "3 2020-10-19 06:44:19  RT @BLACKPINKGLOBAL: RT &amp; REPLY:\\n\\nI vote...\n",
       "4 2020-10-19 06:44:19  RT @TODAYonline: Blackpink's Lisa Is M.A.C's F...\n",
       "5 2020-10-19 06:44:19  RT @jnyloops: hi! this is a new account dedica...\n",
       "6 2020-10-19 06:44:19  RT @TeamLisaEU: ðŸ“Œ #LISA: I have always been a ...\n",
       "7 2020-10-19 06:44:19  RT @BLACKPINKGLOBAL: #JISOO #JENNIE #ROSÃ‰ for ...\n",
       "8 2020-10-19 06:44:18  RT @BLACKPINK: 'THE ALBUM' JACKET MAKING FILM\\...\n",
       "9 2020-10-19 06:44:18  RT @BLINKVotingPage: [PCA 2020]\\n\\nLast year, ..."
      ]
     },
     "execution_count": 161,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchsetdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rB-MTIwRqTyo"
   },
   "source": [
    "# Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JnGGapoY_bQ_"
   },
   "outputs": [],
   "source": [
    "def buildTrainingSet(corpusFile, tweetDataFile):\n",
    "#use corpusFile which has id keys for tweets to grab from twitter API as to not violate any developer rules\n",
    "    corpus=[]\n",
    "    \n",
    "    with open(corpusFile,'r') as csvfile:\n",
    "        lineReader = csv.reader(csvfile, delimiter=',', quotechar=\"\\\"\")\n",
    "        for row in lineReader:\n",
    "            corpus.append({\"tweet_id\":row[2], \"label\":row[1], \"topic\":row[0]})\n",
    "\n",
    "    rate_limit=180\n",
    "    sleep_time=900/180\n",
    "    trainingDataSet=[]\n",
    "    for tweet in corpus:\n",
    "        try:\n",
    "            status = twitter_api.GetStatus(tweet[\"tweet_id\"])\n",
    "            print(\"Tweet fetched\" + status.text)\n",
    "            tweet[\"text\"] = status.text\n",
    "            trainingDataSet.append(tweet)\n",
    "            time.sleep(sleep_time)\n",
    "        except: \n",
    "            continue\n",
    "    # Now we write them to the empty CSV file\n",
    "    with open(tweetDataFile,'wb') as csvfile:\n",
    "        linewriter=csv.writer(csvfile,delimiter=',',quotechar=\"\\\"\")\n",
    "        for tweet in trainingDataSet:\n",
    "            try:\n",
    "                linewriter.writerow([tweet[\"tweet_id\"],tweet[\"text\"],tweet[\"label\"],tweet[\"topic\"]])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return trainingDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0ClwAi1_gv4"
   },
   "outputs": [],
   "source": [
    "#corpusFile = \"/YOURFILEPATH/corpus.csv\"\n",
    "#tweetDataFile = \"/YOURFILEPATH/tweetDataFile.csv\"\n",
    "#trainingData = buildTrainingSet(corpusFile, tweetDataFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQpXEJwpiOXT"
   },
   "outputs": [],
   "source": [
    "# Once we ran buildTrainingSet once (takes a few hours), now we have csv of all the tweets for training\n",
    "\n",
    "trainingdata = pd.read_csv(\"/YOURFILEPATH/full-corpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "R7CMRZ25jLgw",
    "outputId": "9d53a783-3d3d-4fd8-ea7a-d7717ce1ee7d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TweetId</th>\n",
       "      <th>TweetDate</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126415614616154112</td>\n",
       "      <td>Tue Oct 18 21:53:25 +0000 2011</td>\n",
       "      <td>Now all @Apple has to do is get swype on the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126404574230740992</td>\n",
       "      <td>Tue Oct 18 21:09:33 +0000 2011</td>\n",
       "      <td>@Apple will be adding more carrier support to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126402758403305474</td>\n",
       "      <td>Tue Oct 18 21:02:20 +0000 2011</td>\n",
       "      <td>Hilarious @youtube video - guy does a duet wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126397179614068736</td>\n",
       "      <td>Tue Oct 18 20:40:10 +0000 2011</td>\n",
       "      <td>@RIM you made it too easy for me to switch to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126395626979196928</td>\n",
       "      <td>Tue Oct 18 20:34:00 +0000 2011</td>\n",
       "      <td>I just realized that the reason I got into twi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>twitter</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>126855687060987904</td>\n",
       "      <td>Thu Oct 20 03:02:07 +0000 2011</td>\n",
       "      <td>me re copÃ¨ con #twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>twitter</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>126855171702661120</td>\n",
       "      <td>Thu Oct 20 03:00:04 +0000 2011</td>\n",
       "      <td>Buenas noches genteeee :) #twitter los quieroo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>twitter</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>126854999442587648</td>\n",
       "      <td>Thu Oct 20 02:59:23 +0000 2011</td>\n",
       "      <td>#twitter tiene la mala costumbre de ponerce bn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5111</th>\n",
       "      <td>twitter</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>126854818101858304</td>\n",
       "      <td>Thu Oct 20 02:58:40 +0000 2011</td>\n",
       "      <td>Oi @flaviasansi. Muito bem vinda ao meu #Twitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5112</th>\n",
       "      <td>twitter</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>126854423317188608</td>\n",
       "      <td>Thu Oct 20 02:57:06 +0000 2011</td>\n",
       "      <td>Eles arrastaram os barcos para a praia, deixar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5113 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Topic  ...                                          TweetText\n",
       "0       apple  ...  Now all @Apple has to do is get swype on the i...\n",
       "1       apple  ...  @Apple will be adding more carrier support to ...\n",
       "2       apple  ...  Hilarious @youtube video - guy does a duet wit...\n",
       "3       apple  ...  @RIM you made it too easy for me to switch to ...\n",
       "4       apple  ...  I just realized that the reason I got into twi...\n",
       "...       ...  ...                                                ...\n",
       "5108  twitter  ...                            me re copÃ¨ con #twitter\n",
       "5109  twitter  ...  Buenas noches genteeee :) #twitter los quieroo...\n",
       "5110  twitter  ...  #twitter tiene la mala costumbre de ponerce bn...\n",
       "5111  twitter  ...  Oi @flaviasansi. Muito bem vinda ao meu #Twitt...\n",
       "5112  twitter  ...  Eles arrastaram os barcos para a praia, deixar...\n",
       "\n",
       "[5113 rows x 5 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "o6JkW57jnpJ5",
    "outputId": "7c88a08f-015f-4877-de0a-bdec454a2a7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2333\n",
       "4    1689\n",
       "0     572\n",
       "2     519\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingdata['Sentiment'] = trainingdata['Sentiment'].map({'negative':0,'neutral':1,'positive':2,'irrelevant':4})\n",
    "trainingdata['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S85m5ppCi6Of"
   },
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5u6CYH3pamy"
   },
   "outputs": [],
   "source": [
    "def cleanup_text(docs, logging=False):\n",
    "    texts = []\n",
    "    counter = 1\n",
    "    table = str.maketrans({key: None for key in string.punctuation})\n",
    "\n",
    "    for doc in docs:\n",
    "        if counter % 1000 == 0 and logging:\n",
    "            print(\"Processed %d out of %d documents.\" % (counter, len(docs)))\n",
    "        counter += 1\n",
    "        doc = nlp(doc, disable=['parser', 'ner'])\n",
    "        #Convert text to lowercase, strip whitespace and remove personal pronouns\n",
    "        tokens = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != '-PRON-']\n",
    "        #Remove stopwords\n",
    "        tokens = [tok.translate(table) for tok in tokens if tok not in stopwords ]\n",
    "        tokens = ' '.join(tokens)\n",
    "        #Remove extra whitespace\n",
    "        tokens = ' '.join(tokens.split())\n",
    "        # remove URLs\n",
    "        tokens = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', tokens)\n",
    "        # remove usernames\n",
    "        tokens = re.sub('@[^\\s]+', 'AT_USER', tokens)\n",
    "        # remove the # in #hashtag\n",
    "        tokens = re.sub(r'#([^\\s]+)', r'\\1', tokens)\n",
    "        # remove repeated characters (helloooooooo into hello)\n",
    "        #tokens = word_tokenize(tokens)\n",
    "        texts.append(tokens)\n",
    "    return pd.Series(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Dy95WY7czOK"
   },
   "outputs": [],
   "source": [
    "trainingdata = trainingdata[['TweetText','Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "XHbn8r9Opa5U",
    "outputId": "c871c106-1a45-4d38-b4d9-46846d6c9087"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 out of 5113 documents.\n",
      "Processed 2000 out of 5113 documents.\n",
      "Processed 3000 out of 5113 documents.\n",
      "Processed 4000 out of 5113 documents.\n",
      "Processed 5000 out of 5113 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "trainingdata['data_clean']= cleanup_text(trainingdata['TweetText'],logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "QEOCNc1yn2e2",
    "outputId": "3dc86f51-5e6b-4bb7-8106-c330ce7e6a5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TweetText     0\n",
       "Sentiment     0\n",
       "data_clean    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 170,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingdata.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmz-KRtSxcim"
   },
   "outputs": [],
   "source": [
    "trainingdata = trainingdata[trainingdata['Sentiment'] < 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJ2NAFSPrUf5"
   },
   "outputs": [],
   "source": [
    "train,test = train_test_split(trainingdata,test_size=0.2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E-xW6Ko1kt7C"
   },
   "outputs": [],
   "source": [
    "test = test.sort_index()\n",
    "train = train.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "HGDQzL3PpbD3",
    "outputId": "bfc2f699-5734-43f1-8164-9c2a3ad40252"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "      <th>data_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-19 06:44:20</td>\n",
       "      <td>RT @blackpinkbabo: JENNIE LIKES THAT! Look at ...</td>\n",
       "      <td>rt blackpinkbabo jennie likes look jennie â€™s l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-19 06:44:20</td>\n",
       "      <td>RT @ygent_official: #BLACKPINK 'Kill This Love...</td>\n",
       "      <td>rt ygentofficial blackpink kill love dance pra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-19 06:44:19</td>\n",
       "      <td>RT @13chnwar: rosie is whipped ðŸ˜‚\\n\\n#JENNIE #ì œ...</td>\n",
       "      <td>rt 13chnwar rosie whip ðŸ˜‚ jennie ì œë‹ˆ rosÃ© ë¡œì œ bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-19 06:44:19</td>\n",
       "      <td>RT @BLACKPINKGLOBAL: RT &amp;amp; REPLY:\\n\\nI vote...</td>\n",
       "      <td>rt blackpinkglobal rt amp reply vote icecream ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-19 06:44:19</td>\n",
       "      <td>RT @TODAYonline: Blackpink's Lisa Is M.A.C's F...</td>\n",
       "      <td>rt todayonline blackpink s lisa mac s first fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-10-19 06:44:19</td>\n",
       "      <td>RT @jnyloops: hi! this is a new account dedica...</td>\n",
       "      <td>rt jnyloop hi new account dedicate blackpink â€™...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-10-19 06:44:19</td>\n",
       "      <td>RT @TeamLisaEU: ðŸ“Œ #LISA: I have always been a ...</td>\n",
       "      <td>rt teamlisaeu ðŸ“Œ lisa always big fan mac like b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-10-19 06:44:19</td>\n",
       "      <td>RT @BLACKPINKGLOBAL: #JISOO #JENNIE #ROSÃ‰ for ...</td>\n",
       "      <td>rt blackpinkglobal jisoo jennie rosÃ© adidas or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-10-19 06:44:18</td>\n",
       "      <td>RT @BLACKPINK: 'THE ALBUM' JACKET MAKING FILM\\...</td>\n",
       "      <td>rt blackpink album jacket making film blackpin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-10-19 06:44:18</td>\n",
       "      <td>RT @BLINKVotingPage: [PCA 2020]\\n\\nLast year, ...</td>\n",
       "      <td>rt blinkvotingpage pca 2020 last year blackpin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Datetime  ...                                         data_clean\n",
       "0 2020-10-19 06:44:20  ...  rt blackpinkbabo jennie likes look jennie â€™s l...\n",
       "1 2020-10-19 06:44:20  ...  rt ygentofficial blackpink kill love dance pra...\n",
       "2 2020-10-19 06:44:19  ...  rt 13chnwar rosie whip ðŸ˜‚ jennie ì œë‹ˆ rosÃ© ë¡œì œ bla...\n",
       "3 2020-10-19 06:44:19  ...  rt blackpinkglobal rt amp reply vote icecream ...\n",
       "4 2020-10-19 06:44:19  ...  rt todayonline blackpink s lisa mac s first fe...\n",
       "5 2020-10-19 06:44:19  ...  rt jnyloop hi new account dedicate blackpink â€™...\n",
       "6 2020-10-19 06:44:19  ...  rt teamlisaeu ðŸ“Œ lisa always big fan mac like b...\n",
       "7 2020-10-19 06:44:19  ...  rt blackpinkglobal jisoo jennie rosÃ© adidas or...\n",
       "8 2020-10-19 06:44:18  ...  rt blackpink album jacket making film blackpin...\n",
       "9 2020-10-19 06:44:18  ...  rt blinkvotingpage pca 2020 last year blackpin...\n",
       "\n",
       "[10 rows x 3 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchsetdf['data_clean'] = cleanup_text(searchsetdf['Text'],logging=True)\n",
    "searchsetdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuBJ4cCLhDqH"
   },
   "source": [
    "# AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLyYqBl9hJcB"
   },
   "outputs": [],
   "source": [
    "automltraining = trainingdata\n",
    "automltraining = automltraining[['TweetText','Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "sqHdti_xhC7A",
    "outputId": "06da5aa7-1c3e-4b8c-eb6a-9fefd5d1361c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetText</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Now all @Apple has to do is get swype on the i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Apple will be adding more carrier support to ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hilarious @youtube video - guy does a duet wit...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@RIM you made it too easy for me to switch to ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I just realized that the reason I got into twi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4537</th>\n",
       "      <td>@madtruckman 'Modern Day Autograph\", I like th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4538</th>\n",
       "      <td>62 Ways to Use #Twitter for Business: http://t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4539</th>\n",
       "      <td>Log off #Facebook On #Twitter , But I Think i'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4540</th>\n",
       "      <td>\"#twitter's dumb, I don't like it.\"  Hush up, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4541</th>\n",
       "      <td>It's almost 4:20. Where is your bong? Is it pa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3424 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              TweetText  Sentiment\n",
       "0     Now all @Apple has to do is get swype on the i...          2\n",
       "1     @Apple will be adding more carrier support to ...          2\n",
       "2     Hilarious @youtube video - guy does a duet wit...          2\n",
       "3     @RIM you made it too easy for me to switch to ...          2\n",
       "4     I just realized that the reason I got into twi...          2\n",
       "...                                                 ...        ...\n",
       "4537  @madtruckman 'Modern Day Autograph\", I like th...          1\n",
       "4538  62 Ways to Use #Twitter for Business: http://t...          1\n",
       "4539  Log off #Facebook On #Twitter , But I Think i'...          1\n",
       "4540  \"#twitter's dumb, I don't like it.\"  Hush up, ...          1\n",
       "4541  It's almost 4:20. Where is your bong? Is it pa...          1\n",
       "\n",
       "[3424 rows x 2 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automltraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "BHrdOwaPhNAI",
    "outputId": "441677b7-eaf9-46c6-9154-aa91663eb595"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2333\n",
       "0     572\n",
       "2     519\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automltraining['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdfdNUeGhRef"
   },
   "outputs": [],
   "source": [
    "#write to csv for automl training data, only need to run once \n",
    "\n",
    "#automltraining.to_csv(\"/content/gdrive/My Drive/Colab Notebooks/portfolio/twitter/automltraining.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6hDR0Twms1S"
   },
   "outputs": [],
   "source": [
    "searchsetexport = searchsetdf['data_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhaOhT86zJPe"
   },
   "outputs": [],
   "source": [
    "#export each tweet as separate txt file in folder as per AutoML batchpredict file input requirements\n",
    "\n",
    "for key in searchsetdf.index.unique(): \n",
    "    searchsetexport = searchsetdf[searchsetdf.index == key]   \n",
    "    searchsetexport['data_clean'].to_csv(\"/content/gdrive/My Drive/Colab Notebooks/portfolio/twitter/tweets/%s.txt\" % key, header=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8aDgwM-c2Qpk"
   },
   "outputs": [],
   "source": [
    "#write a CSV of each txt file name as reference as per AutoML batchpredict file input requirements\n",
    "\n",
    "tweetlist = []\n",
    "for i in searchsetdf.index.unique():\n",
    "  tweetlist.append(\"gs://YOURBUCKETURI/%i.txt\" % i)\n",
    "  df = pd.DataFrame(tweetlist)\n",
    "  df.to_csv(\"/YOURFILEPATH/tweetlist.csv\",index=None,header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCxbsEw8jXhz"
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgh_VcjrlsU2"
   },
   "source": [
    "## bagofwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xj1AS3GGd1Az"
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train['data_clean'])\n",
    "X_train_counts = X_train_counts.toarray()\n",
    "\n",
    "X_test_counts = count_vect.transform(test['data_clean']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bdTgyR_zlvGM"
   },
   "outputs": [],
   "source": [
    "searchset_counts = count_vect.fit_transform(searchsetdf['data_clean'])\n",
    "searchset_counts = searchset_counts.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yyYu79tmXpr"
   },
   "source": [
    "## tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dUGPnvEJexPx"
   },
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf = X_train_tfidf.toarray()\n",
    "\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "nNKuZod7l3g5",
    "outputId": "3c5f28f4-a9f3-402b-92ae-0179d23de165"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 98)"
      ]
     },
     "execution_count": 185,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchset_tfidf = tfidf_transformer.fit_transform(searchset_counts)\n",
    "searchset_tfidf = searchset_tfidf.toarray()\n",
    "\n",
    "searchset_tfidf = tfidf_transformer.transform(searchset_counts).toarray()\n",
    "searchset_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYwWXSM0mPgC"
   },
   "source": [
    "## glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "mllHUSfEgBzx",
    "outputId": "70b0286a-4abd-415a-b35f-425d929023d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 out of 2739 documents.\n",
      "Processed 500 out of 2739 documents.\n",
      "Processed 1000 out of 2739 documents.\n",
      "Processed 1500 out of 2739 documents.\n",
      "Processed 2000 out of 2739 documents.\n",
      "Processed 2500 out of 2739 documents.\n",
      "Processed 0 out of 685 documents.\n"
     ]
    }
   ],
   "source": [
    "train_vec_glove = []\n",
    "counter = 0\n",
    "for doc in nlp.pipe(train[\"data_clean\"], batch_size=500):\n",
    "    if counter % 500 == 0:\n",
    "        print(\"Processed %d out of %d documents.\" % (counter, len(train[\"data_clean\"])))\n",
    "    if doc.has_vector:\n",
    "        train_vec_glove.append(doc.vector)\n",
    "    else:\n",
    "        train_vec_glove.append(np.zeros((300,), dtype=\"float32\"))\n",
    "    counter +=1\n",
    "        \n",
    "train_vec_glove = np.array(train_vec_glove)\n",
    "\n",
    "counter = 0\n",
    "test_vec_glove = []\n",
    "for doc in nlp.pipe(test[\"data_clean\"], batch_size=500):\n",
    "    if counter % 1000 == 0:\n",
    "        print(\"Processed %d out of %d documents.\" % (counter, len(test[\"data_clean\"])))\n",
    "    if doc.has_vector:\n",
    "        test_vec_glove.append(doc.vector)\n",
    "    else:# If doc doesn't have a vector, then fill it with zeros.\n",
    "        test_vec_glove.append(np.zeros((300,), dtype=\"float32\"))\n",
    "    counter +=1\n",
    "     \n",
    "test_vec_glove = np.array(test_vec_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "tpWAxYDOgKsj",
    "outputId": "87a5c747-8da5-45c5-eee5-c9197085bcba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train word vector shape: (2739, 96)\n",
      "Test word vector shape: (685, 96)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train word vector shape:\", train_vec_glove.shape)\n",
    "print(\"Test word vector shape:\", test_vec_glove.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "yNx3zvSpG6eb",
    "outputId": "16b55cfe-45d7-4d27-bae9-c1ccaefb345b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 out of 10 documents.\n",
      "CPU times: user 35.7 ms, sys: 3.07 ms, total: 38.8 ms\n",
      "Wall time: 38.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "search_vec_glove = []\n",
    "counter = 0\n",
    "for doc in nlp.pipe(searchsetdf[\"data_clean\"], batch_size=500):\n",
    "    if counter % 500 == 0:\n",
    "        print(\"Processed %d out of %d documents.\" % (counter, len(searchsetdf[\"data_clean\"])))\n",
    "    if doc.has_vector:\n",
    "        search_vec_glove.append(doc.vector)\n",
    "    else:\n",
    "        search_vec_glove.append(np.zeros((300,), dtype=\"float32\"))\n",
    "    counter +=1\n",
    "    \n",
    "search_vec_glove = np.array(search_vec_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "3i4lsHz5cPBU",
    "outputId": "1bf4e841-403b-45f1-a01c-09d6f7f8ce99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search word vector shape: (10, 96)\n"
     ]
    }
   ],
   "source": [
    "print(\"Search word vector shape:\", search_vec_glove.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIH3GDpSmghB"
   },
   "source": [
    "# Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAYXGWyL5qXK"
   },
   "source": [
    "## Keras Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ovMShLAmoHA"
   },
   "outputs": [],
   "source": [
    "# Transform labels into one hot encoded format.\n",
    "\n",
    "y_train_one = label_binarize(train[\"Sentiment\"], classes=train[\"Sentiment\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YOKKmJyCVT4"
   },
   "source": [
    "### Glove NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7GFZj6AZe-Ew",
    "outputId": "a4b779cf-dada-4993-bf6e-c51e62347cd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 1.2118 - acc: 0.5907 - val_loss: 0.4764 - val_acc: 0.9599\n",
      "Epoch 2/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.8945 - acc: 0.6227 - val_loss: 0.4895 - val_acc: 0.9635\n",
      "Epoch 3/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.8603 - acc: 0.6450 - val_loss: 1.0694 - val_acc: 0.3394\n",
      "Epoch 4/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.8650 - acc: 0.6389 - val_loss: 0.9931 - val_acc: 0.4343\n",
      "Epoch 5/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.8683 - acc: 0.6264 - val_loss: 0.6621 - val_acc: 0.8540\n",
      "Epoch 6/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.8381 - acc: 0.6345 - val_loss: 0.6093 - val_acc: 0.9234\n",
      "Epoch 7/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.8267 - acc: 0.6483 - val_loss: 0.3979 - val_acc: 0.9964\n",
      "Epoch 8/100\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.7846 - acc: 0.6718 - val_loss: 0.4799 - val_acc: 0.9161\n",
      "Epoch 9/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.7726 - acc: 0.6673 - val_loss: 0.4664 - val_acc: 0.9270\n",
      "Epoch 10/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.7486 - acc: 0.6730 - val_loss: 0.4677 - val_acc: 0.9161\n",
      "Epoch 11/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.7335 - acc: 0.6755 - val_loss: 0.5326 - val_acc: 0.8358\n",
      "Epoch 12/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.7175 - acc: 0.6990 - val_loss: 0.4605 - val_acc: 0.9234\n",
      "Epoch 13/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.6897 - acc: 0.7059 - val_loss: 0.9240 - val_acc: 0.5620\n",
      "Epoch 14/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.7545 - acc: 0.6787 - val_loss: 0.3990 - val_acc: 0.9161\n",
      "Epoch 15/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.7033 - acc: 0.6929 - val_loss: 0.5097 - val_acc: 0.8577\n",
      "Epoch 16/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.6651 - acc: 0.7156 - val_loss: 0.6086 - val_acc: 0.8175\n",
      "Epoch 17/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.7182 - acc: 0.7051 - val_loss: 0.4178 - val_acc: 0.8905\n",
      "Epoch 18/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.6609 - acc: 0.7176 - val_loss: 0.4008 - val_acc: 0.9124\n",
      "Epoch 19/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.6363 - acc: 0.7294 - val_loss: 0.6690 - val_acc: 0.7482\n",
      "Epoch 20/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.6363 - acc: 0.7363 - val_loss: 0.2718 - val_acc: 0.9453\n",
      "Epoch 21/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.5892 - acc: 0.7529 - val_loss: 0.3831 - val_acc: 0.8796\n",
      "Epoch 22/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.5800 - acc: 0.7562 - val_loss: 0.4294 - val_acc: 0.8650\n",
      "Epoch 23/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.5302 - acc: 0.7817 - val_loss: 0.4867 - val_acc: 0.8394\n",
      "Epoch 24/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.5213 - acc: 0.7858 - val_loss: 0.6341 - val_acc: 0.7482\n",
      "Epoch 25/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.5397 - acc: 0.7712 - val_loss: 0.4860 - val_acc: 0.8321\n",
      "Epoch 26/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.4987 - acc: 0.7947 - val_loss: 0.5241 - val_acc: 0.7993\n",
      "Epoch 27/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.5113 - acc: 0.7895 - val_loss: 0.3886 - val_acc: 0.8796\n",
      "Epoch 28/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.4782 - acc: 0.8028 - val_loss: 0.4630 - val_acc: 0.8358\n",
      "Epoch 29/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.4567 - acc: 0.8150 - val_loss: 0.5537 - val_acc: 0.7920\n",
      "Epoch 30/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.4610 - acc: 0.8138 - val_loss: 0.4848 - val_acc: 0.8686\n",
      "Epoch 31/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.4132 - acc: 0.8345 - val_loss: 0.5915 - val_acc: 0.7445\n",
      "Epoch 32/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.4016 - acc: 0.8398 - val_loss: 0.7631 - val_acc: 0.6898\n",
      "Epoch 33/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.4394 - acc: 0.8272 - val_loss: 0.3911 - val_acc: 0.8723\n",
      "Epoch 34/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.4012 - acc: 0.8333 - val_loss: 0.6322 - val_acc: 0.7774\n",
      "Epoch 35/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3851 - acc: 0.8450 - val_loss: 1.3839 - val_acc: 0.4234\n",
      "Epoch 36/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.6831 - acc: 0.7363 - val_loss: 0.5508 - val_acc: 0.7591\n",
      "Epoch 37/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.4382 - acc: 0.8235 - val_loss: 0.5711 - val_acc: 0.7628\n",
      "Epoch 38/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3654 - acc: 0.8544 - val_loss: 0.5052 - val_acc: 0.8175\n",
      "Epoch 39/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3365 - acc: 0.8755 - val_loss: 0.2491 - val_acc: 0.9197\n",
      "Epoch 40/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.4986 - acc: 0.8020 - val_loss: 0.4593 - val_acc: 0.8358\n",
      "Epoch 41/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3786 - acc: 0.8527 - val_loss: 0.4352 - val_acc: 0.8212\n",
      "Epoch 42/100\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3434 - acc: 0.8722 - val_loss: 0.4849 - val_acc: 0.8139\n",
      "Epoch 00042: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define number of epochs\n",
    "\n",
    "epochs = 100\n",
    "ann_layers = 1\n",
    "#Standard fully connected network\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', kernel_initializer='he_normal', input_dim=96))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "for i in range(ann_layers):\n",
    "    model.add(Dense(512, activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='loss', patience=3, verbose=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "ann_glove = model.fit(train_vec_glove, y_train_one, epochs=epochs,validation_split=0.1, verbose=1,\n",
    "                      callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "PC3eau7wC_IQ",
    "outputId": "84acfe22-64f8-4c08-86e2-6851d800bf20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 87.22109794616699\n",
      "Validation accuracy: 81.38686418533325 for the Glove embeddings.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training accuracy: {100*ann_glove.history['acc'][-1]}\")\n",
    "print(f\"Validation accuracy: {100*ann_glove.history['val_acc'][-1]} for the Glove embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "kpe55wH-fWB0",
    "outputId": "ecf6a4d1-d883-4521-b5fa-99e86d10278a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Negative(0), Neutral(1), and Positive(2) Tweets for keyword: blackpink \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    80.0\n",
       "1    10.0\n",
       "0    10.0\n",
       "Name: glovelabel, dtype: float64"
      ]
     },
     "execution_count": 212,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict class labels on search set\n",
    "\n",
    "searchlabelsglove = np.argmax(model.predict(search_vec_glove), axis=-1)\n",
    "searchsetdf['glovelabel'] = searchlabelsglove\n",
    "\n",
    "print(f'Percentage of Negative(0), Neutral(1), and Positive(2) Tweets for keyword: {text_query} from a total of {count} tweets')\n",
    "searchsetdf['glovelabel'].value_counts(normalize=True,sort=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zjTtuXCjA2mH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Twitter_colab",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
